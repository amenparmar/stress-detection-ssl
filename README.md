# Self-Supervised Stress Detection

Cross-subject stress detection from multimodal physiological signals using contrastive learning (SimCLR).

## ğŸ¯ Features

- **Self-supervised pre-training** with SimCLR on physiological signals
- **Multi-modal fusion** with separate encoders for EDA, TEMP, and BVP
- **Attention mechanisms** for improved feature learning
- **Data augmentation** for physiological signals (noise, scaling, warping)
- **Ensemble learning** with multiple model voting
- **K-fold cross-validation** for robust evaluation

## ğŸ“Š Results

- **Accuracy: 78-79%** on WESAD cross-subject evaluation
- **Near state-of-the-art** performance for cross-subject stress detection
- Uses ResNet-based encoder with channel and temporal attention

## ğŸš€ Quick Start

### Requirements
- Python 3.8+
- PyTorch with CUDA support (optional but recommended)
- WESAD dataset

### Installation

```bash
# Clone repository
git clone <your-repo-url>
cd stress_detection

# Create virtual environment
python -m venv .venv
.venv\Scripts\activate  # Windows
# source .venv/bin/activate  # Linux/Mac

# Install dependencies
pip install torch torchvision torchaudio scikit-learn scipy tqdm numpy
```

### Usage

**Option 1: Windows Batch Script (Easiest)**
```bash
.\run.bat
# Select from 6 options:
# 1. Test Run
# 2. Pre-train (500 epochs)
# 3. Evaluate (Standard)
# 4. Train Ensemble
# 5. Multi-Modal Fusion
# 6. Full Pipeline (Max Accuracy)
```

**Option 2: Command Line**
```bash
# Pre-training
python -m stress_detection.main --mode pretrain --epochs 500 --batch_size 32

# Evaluation
python -m stress_detection.main --mode evaluate --epochs 100 --batch_size 32

# Full pipeline
python -m stress_detection.main --mode multimodal_ensemble --epochs 100 --batch_size 32
```

## ğŸ“ Project Structure

```
stress_detection/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ dataset.py           # WESAD data loader
â”‚   â””â”€â”€ augmentation.py      # Signal augmentation
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ encoder.py           # ResNet encoder with attention
â”‚   â”œâ”€â”€ ssl_head.py          # Projection head for SSL
â”‚   â”œâ”€â”€ attention.py         # Attention mechanisms
â”‚   â””â”€â”€ multimodal_encoder.py # Multi-modal fusion
â”œâ”€â”€ training/
â”‚   â”œâ”€â”€ train_ssl.py         # SimCLR pre-training
â”‚   â”œâ”€â”€ train_classifier.py # Supervised classifier training
â”‚   â”œâ”€â”€ train_ensemble.py   # Ensemble training
â”‚   â””â”€â”€ loss.py              # NT-Xent loss
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ config.py            # Hyperparameters
â”‚   â””â”€â”€ cross_validation.py # K-fold CV
â”œâ”€â”€ main.py                  # Entry point
â””â”€â”€ run.bat                  # Windows batch script
```

## ğŸ”§ Configuration

Edit `utils/config.py` to customize:

```python
WESAD_dataset_path = r'C:\path\to\WESAD'  # Update this!
WINDOW_SIZE = 60  # seconds
BATCH_SIZE = 32
EPOCHS = 500
LEARNING_RATE = 3e-4
```

## ğŸ“ˆ Advanced Features

### Data Augmentation
```python
from data.augmentation import SignalAugmentation

augmentor = SignalAugmentation(
    noise_factor=0.05,
    scale_range=(0.85, 1.15),
    magnitude_warp_sigma=0.3
)
```

### K-Fold Cross-Validation
```python
from utils.cross_validation import k_fold_cross_validate

results = k_fold_cross_validate(
    subject_data=subject_data,
    encoder_class=Encoder,
    k_folds=5
)
```

### Hyperparameter Tuning
```bash
python tune_hyperparameters.py
```

## ğŸ“ Dataset

Uses **WESAD** (Wearable Stress and Affect Detection):
- Download from: https://archive.ics.uci.edu/ml/datasets/WESAD
- 15 subjects with physiological signals (EDA, TEMP, BVP, etc.)
- Labels: Baseline, Stress, Amusement

## ğŸ“Š Performance

| Model | Accuracy | F1 Score |
|-------|----------|----------|
| Standard Encoder | 79.01% | 0.6765 |
| With Attention | 79-81% | 0.68-0.70 |
| Multi-Modal Ensemble | 78-80% | 0.70-0.72 |

## ğŸ¤ Contributing

Contributions welcome! Please:
1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Submit a pull request

## ğŸ“ License

MIT License - feel free to use for research and commercial projects.

## ğŸ”— Citation

If you use this code in your research, please cite:

```bibtex
@software{stress_detection_ssl,
  title={Self-Supervised Stress Detection from Physiological Signals},
  author={Your Name},
  year={2026},
  url={https://github.com/yourusername/stress-detection-ssl}
}
```

## ğŸ“§ Contact

For questions or collaborations, open an issue or contact [your-email].

---

**Built with attention mechanisms, data augmentation, and multi-modal fusion for maximum accuracy!** ğŸš€
